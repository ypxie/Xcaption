{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk as nl\n",
    "import matplotlib.pyplot as plt\n",
    "from json import loads\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from random import randint, choice\n",
    "from itertools import chain\n",
    "from numpy import mean, std\n",
    "from copy import copy\n",
    "import numpy as np\n",
    "\n",
    "d_corpus = \"../Annotation/\"\n",
    "f_tempfile = \"list_descriptions.txt\"\n",
    "f_wordswap = \"word_swaps.json\"\n",
    "blank = \"____\"\n",
    "conclusion = \"conclusion\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LoadCorpus(directory):\n",
    "    \"\"\"Returns a list of annotations found in the directory given in the string 'directory'.\"\"\"\n",
    "    files = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "    corpus = []\n",
    "    for c_file in files:\n",
    "        corpus.append(loads(open(directory + c_file).read()))\n",
    "    return corpus\n",
    "\n",
    "def LoadWords(fname):\n",
    "    \"\"\"Returns a dictionary of categories to be passed to GenerateParaphrases(). These categories\n",
    "    are loaded from a json file with the name 'fname'.\"\"\"\n",
    "    json_wordswaps = open(fname).read()\n",
    "    return loads(json_wordswaps)\n",
    "\n",
    "def Dict2Sentence(annotation_dict):\n",
    "    \"\"\"Converts the values in 'annotation_dict' into a string by concatenating them.\"\"\"\n",
    "    annotation_dict_copy = copy(annotation_dict)\n",
    "    annotation_dict_copy.pop(\"conclusion\")\n",
    "    sentence = ''\n",
    "    for i in annotation_dict_copy.values():\n",
    "        sentence = sentence + i[1].capitalize() + ' '\n",
    "    return sentence\n",
    "\n",
    "def LoadTemplates(ftemp):\n",
    "    \"\"\"Returns a list of swappable phrases to be passed to GenerateParaphrases\"\"\"\n",
    "    tempfile = open(ftemp, 'r')\n",
    "    tempfile.next()    # skip the header line\n",
    "    phrases = []\n",
    "    for c_line in tempfile:\n",
    "        c_line_split = c_line.split('\\t')\n",
    "        c_line_0 = c_line_split[0]\n",
    "        c_line_1 = map(int, c_line_split[1].split(' '))\n",
    "        c_line_2 = c_line_split[2].translate(None, '\\n').split(' ')\n",
    "        #c_line_2 = map(int, c_line_2) \n",
    "        c_line_3 = c_line_split[3].translate(None, '\\n').split(' ')\n",
    "        phrases.append([c_line_0, c_line_1, c_line_2, c_line_3])\n",
    "    return phrases\n",
    "\n",
    "def GenerateParaphrases(candidate, phrases, wordswaps, n_paraphrases=10):\n",
    "    \"\"\"Pass one candidate at a time.\"\"\"\n",
    "    keys_cats = list(wordswaps.keys())\n",
    "    keys_cats.remove(\"conclusion\")\n",
    "    categories = {str(wordswaps[i][0]): i for i in keys_cats}\n",
    "    n_phrases = len(phrases)\n",
    "    paraphrases = []\n",
    "    for i in range(n_paraphrases):\n",
    "        c_degrees = {cat: candidate[cat][0] for cat in categories.values()}    # dict with annotation info\n",
    "        cats_used = []\n",
    "        sentences = []   # list of sentences \n",
    "        count = 0        # number of sentences\n",
    "        while not (len(list(c_degrees.keys()))==0) and count < 5:\n",
    "            # select a category\n",
    "            cats_unused = list(c_degrees.keys())\n",
    "            c_cat = choice(cats_unused)        # randomly select unused category\n",
    "            c_cat_degree = c_degrees[c_cat]    # get degree of category for this file\n",
    "            \n",
    "            # selects idxs from phrase that belong to unused category c_cat\n",
    "            c_phrases_idxs = [i for i in range(n_phrases) if (wordswaps[c_cat][0] in phrases[i][1]) \n",
    "                          and (c_cat_degree in phrases[i][2] or phrases[i][2][0]=='')]\n",
    "            \n",
    "            # build list of idxs for used categories so they are ignored when selecting phrases\n",
    "            c_used_cat_idxs = [[i for i in range(n_phrases) if (wordswaps[c_cat_used][0] in phrases[i][1])] \n",
    "                                   for c_cat_used in cats_used]\n",
    "            c_used_cat_idxs = list(chain.from_iterable(c_used_cat_idxs))    # converts iterable to list\n",
    "            \n",
    "            # select phrase, its category, and degree from list\n",
    "            c_phrases_idxs = [i for i in c_phrases_idxs if i not in c_used_cat_idxs]\n",
    "            c_phrase_selected_idx = choice(c_phrases_idxs)       # randomly select phrase\n",
    "            c_phrase_text = phrases[c_phrase_selected_idx][0]    # text of paraphrase\n",
    "            c_phrase_cats = phrases[c_phrase_selected_idx][1]    # idxs of categories\n",
    "            #c_phrase_degrees = phrases[c_phrase_selected_idx][2] # idxs of degrees\n",
    "            c_phrase_adverbs = phrases[c_phrase_selected_idx][3] # bool to indicate if adverb\n",
    "\n",
    "            # replace blank in phrase with degree\n",
    "            c_categories = [categories[str(i)] for i in c_phrase_cats]\n",
    "            c_phrase_adverbs_list = [int(j) for i, j in zip(c_phrase_cats, c_phrase_adverbs)]\n",
    "            c_phrase_cats_degrees = [c_degrees[i] for i in c_categories]\n",
    "            c_degree_text = [wordswaps[c_category][1][1][c_cat_degree] if is_adv else wordswaps[c_category][1][0][c_cat_degree] \n",
    "                             for c_category, c_cat_degree, is_adv in zip(c_categories, c_phrase_cats_degrees, \n",
    "                                                                         c_phrase_adverbs_list)]\n",
    "            for i in c_degree_text:\n",
    "                c_phrase_text = c_phrase_text.replace(blank, i, 1)\n",
    "\n",
    "            # bookkeeping for loop\n",
    "            sentences.append(c_phrase_text)    # add new sentence to selected sentences\n",
    "            [c_degrees.pop(i) for i in c_categories]    # remove used cat & degree from list to prevent selection\n",
    "            [cats_used.append(i) for i in c_categories] # add category to list of used degrees \n",
    "            count += 1\n",
    "\n",
    "        # capitalize and concatenate list of sentences\n",
    "        paraphrase = ''\n",
    "        for i in sentences:\n",
    "            paraphrase = paraphrase + i.capitalize() + ' '\n",
    "\n",
    "        # add paraphrased sentences to list to be returned\n",
    "        paraphrases.append(paraphrase)\n",
    "    return paraphrases\n",
    "\n",
    "def BleuScore(candidate, references, weights=[0.25, 0.25, 0.25, 0.25]):\n",
    "    return nl.bleu(references, candidate, weights)\n",
    "\n",
    "def ModifiedBleuScore(candidate, references, weights=[0.25, 0.25, 0.25, 0.25]):\n",
    "    n_references = len(references)\n",
    "    assert n_references > 1\n",
    "    \n",
    "    \"\"\"Returns Bleu score for 'candidate' using the list of 'references' and 'weights'.\"\"\"\n",
    "    # compute raw bleu score\n",
    "    raw_bleu = BleuScore(candidate, references, weights)\n",
    "    \n",
    "    # compute bleu score of each reference with the other references\n",
    "    bleu_refs = []\n",
    "    for i in range(1, n_references):\n",
    "        ref_copy = copy(ref_list)\n",
    "        ref_copy.pop(i)\n",
    "        bleu_refs.append(BleuScore(ref_list[i], ref_copy, weights))\n",
    "    \n",
    "    # bleu score normalized by reference mean and std\n",
    "    ref_mean = mean(bleu_refs)\n",
    "    ref_std = std(bleu_refs)\n",
    "    mod_bleu = (raw_bleu-(ref_mean-raw_bleu-ref_std)**2)/ref_mean\n",
    "    if (mod_bleu > 1.0):\n",
    "        mod_bleu = 1\n",
    "    return mod_bleu\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = LoadCorpus(d_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load template sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phrases = LoadTemplates(f_tempfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = LoadWords(f_wordswap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example and Bleu score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polarity is not lost. Mitosis is rare. Moderate nuclear crowding is seen. Nucleoli is absent to inconspicuous. Nuclear features show moderate pleomorphism. \n",
      "\n",
      "\n",
      "The nuclei have moderate pleomorphism and show moderate crowding, with rare mitosis. Basement membrane polarity is negligibly lost. The nucleoli of nuclei are inconspicuous. \n",
      "0.503916950492\n"
     ]
    }
   ],
   "source": [
    "n_references = 2\n",
    "c_data = copy(corpus[0])\n",
    "ref_list = GenerateParaphrases(c_data, phrases, words, n_references)\n",
    "annotation = Dict2Sentence(copy(corpus[0]))\n",
    "#weights = [0.25, 0.25, 0.25, 0.25, 0.125]\n",
    "weights = 0.125*np.ones(8)\n",
    "\n",
    "ground_truth = ''\n",
    "for i in c_data.keys():\n",
    "    if not i==conclusion:\n",
    "        ground_truth = ground_truth + c_data[i][1].capitalize() + ' '\n",
    "print(annotation)\n",
    "print('\\n')\n",
    "print(ref_list[0])\n",
    "print(BleuScore(annotation, ref_list, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot convergence in Bleu score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_references = 50\n",
    "n_files_to_use = 20\n",
    "weights = [0.25, 0.25, 0.25, 0.25]\n",
    "\n",
    "bleu_results = []\n",
    "bleu_std = []\n",
    "for i in range(2, n_references+1):\n",
    "    scores = []\n",
    "    for j in corpus[0:n_files_to_use]:\n",
    "        c_data = copy(j)\n",
    "        ref_list = GenerateParaphrases(c_data, phrases, words, i)\n",
    "        annotation = Dict2Sentence(c_data)\n",
    "        scores.append(BleuScore(annotation, ref_list, weights))\n",
    "    bleu_results.append(mean(scores))\n",
    "    bleu_std.append(std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xc22eeb8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(range(2, n_references+1), bleu_results, 'b', \n",
    "         range(2, n_references+1), [a-b for a, b in zip(bleu_results, bleu_std)], 'r', \n",
    "         range(2, n_references+1), [a+b for a, b in zip(bleu_results, bleu_std)], 'r')\n",
    "plt.title(\"Bleu Score for correct (blue) vs. incorrect (green) translation\")\n",
    "plt.xlabel(\"Number of references\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Bleu score of incorrect translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_references = 50\n",
    "n_files_to_use = 20\n",
    "weights = [0.25, 0.25, 0.25, 0.25]\n",
    "\n",
    "bleu_results = []\n",
    "bleu_std = []\n",
    "for i in range(2, n_references+1):\n",
    "    scores = []\n",
    "    for j in corpus[0:n_files_to_use]:\n",
    "        c_data = copy(j)\n",
    "        ref_list = GenerateParaphrases(c_data, phrases, words, i)\n",
    "        annotation = Dict2Sentence(copy(corpus[n_files_to_use+1]))\n",
    "        scores.append(BleuScore(annotation, ref_list, weights))\n",
    "    bleu_results.append(mean(scores))\n",
    "    bleu_std.append(std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(range(2, n_references+1), bleu_results, 'g', \n",
    "         range(2, n_references+1), [a-b for a, b in zip(bleu_results, bleu_std)], 'orange', \n",
    "         range(2, n_references+1), [a+b for a, b in zip(bleu_results, bleu_std)], 'orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bleu score experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_references = 10\n",
    "n_files_to_use = 1\n",
    "weights = [0.25, 0.25, 0.25, 0.25]\n",
    "\n",
    "scores = []\n",
    "c_data = corpus[0]\n",
    "annotation = Dict2Sentence(c_data)\n",
    "ref_list = GenerateParaphrases(c_data, phrases, words, n_references)\n",
    "bleu_refs = []\n",
    "for i in range(1, n_references):\n",
    "    ref_copy = copy(ref_list)\n",
    "    ref_copy.pop(i)\n",
    "    c_score = BleuScore(ref_list[i], ref_copy, weights)\n",
    "    bleu_refs.append(c_score)\n",
    "    print(c_score)\n",
    "print('\\n')\n",
    "print(BleuScore(annotation, ref_list, weights))\n",
    "print(mean(bleu_refs))\n",
    "print(std(bleu_refs))\n",
    "print(ModifiedBleuScore(annotation, ref_list, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = 0.88\n",
    "b = 0.939\n",
    "c = 0.060\n",
    "print((a-(b-a-c)**2)/b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenting with adjective-adverb conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nl.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word = \"normally\"\n",
    "\n",
    "from itertools import chain\n",
    "from nltk.corpus import wordnet as wn\n",
    "from difflib import get_close_matches as gcm\n",
    "possible_adjectives = [k.name() for k in chain(*[j.pertainyms() for j in chain(*[i.lemmas() for i in wn.synsets(word)])])]\n",
    "get_close_matches(word, possible_adjectives, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word = \"moderately\"\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "s = []\n",
    "winner = \"\"\n",
    "for ss in wn.synsets(word):\n",
    "    for lemmas in ss.lemmas(): # all possible lemmas.\n",
    "        s.append(lemmas)\n",
    "\n",
    "for pers in s:\n",
    "    if len(pers.pertainyms())>0:\n",
    "        posword = pers.pertainyms()[0].name()\n",
    "        if posword[0:3] == word[0:3]:\n",
    "            winner = posword\n",
    "            break\n",
    "\n",
    "print winner # undue"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
